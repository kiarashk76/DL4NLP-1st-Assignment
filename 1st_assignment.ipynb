{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "1st assignment.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kiarashk76/DL4NLP-1st-Assignment/blob/master/1st_assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0WQ-3APuEuP0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#mounting the google drive for accessing the dataset\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uDBJts33E2R3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cp '/content/drive/My Drive/Datasets/imdb-movie-reviews-dataset.zip' '/content/'\n",
        "!unzip imdb-movie-reviews-dataset.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ly3KM1dVF2V0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# listing training directories\n",
        "train_pos = os.listdir('/content/aclImdb/train/pos')\n",
        "for i in range(len(train_pos)):\n",
        "  train_pos[i] = 'pos/' + train_pos[i] \n",
        "  \n",
        "train_neg = os.listdir('/content/aclImdb/train/neg')\n",
        "for i in range(len(train_neg)):\n",
        "  train_neg[i] = 'neg/' + train_neg[i]\n",
        "\n",
        "# listing test directories\n",
        "test_pos = os.listdir('/content/aclImdb/test/pos')\n",
        "for i in range(len(test_pos)):\n",
        "  test_pos[i] = 'pos/' + test_pos[i] \n",
        "  \n",
        "test_neg = os.listdir('/content/aclImdb/test/neg')\n",
        "for i in range(len(test_neg)):\n",
        "  test_neg[i] = 'neg/' + test_neg[i]\n",
        "  \n",
        "# extracting validation directories from training\n",
        "np.random.shuffle(train_pos)\n",
        "np.random.shuffle(train_neg)\n",
        "\n",
        "val_pos = train_pos[0:2500]\n",
        "val_neg = train_neg[0:2500]\n",
        "\n",
        "del train_pos[0:2500]\n",
        "del train_neg[0:2500]\n",
        "\n",
        "# shuffling pos and neg trainings\n",
        "X_train = train_pos +  train_neg \n",
        "y_train = [1] * len(train_pos) + [0] * len(train_neg)\n",
        "\n",
        "np.random.seed(314)\n",
        "np.random.shuffle(X_train) \n",
        "np.random.seed(314) \n",
        "np.random.shuffle(y_train)\n",
        "\n",
        "# creating pos and neg validations\n",
        "X_val = val_pos +  val_neg \n",
        "y_val = [1] * len(val_pos) + [0] * len(val_neg)\n",
        "\n",
        "# creating pos and neg tests\n",
        "X_test = test_pos +  test_neg \n",
        "y_test = [1] * len(test_pos) + [0] * len(test_neg)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "okh296epMnYn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_id2word(vocab):\n",
        "  results = []\n",
        "  for i in vocab:\n",
        "    results.append(i[0])\n",
        "  return results\n",
        "\n",
        "def create_word2id(vocab):\n",
        "  results = dict()\n",
        "  for i in range(len(vocab)):\n",
        "    results[vocab[i][0]] = i\n",
        "  return results"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eiVInEZTMJus",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocab = dict()\n",
        "\n",
        "# extract the 2000 most frequent words in our dataset\n",
        "for address in X_train:\n",
        "  file = open('/content/aclImdb/train/'+address,'r')\n",
        "  txt = file.read().strip().lower()\n",
        "  words = txt.split()\n",
        "  for w in words:\n",
        "    if w in vocab:\n",
        "      vocab[w] += 1\n",
        "    else:\n",
        "      vocab[w] = 1\n",
        "\n",
        "\n",
        "vocab = sorted(vocab.items(), key=lambda x: x[1], reverse=True)\n",
        "vocab = vocab[0:2000]\n",
        "\n",
        "id2word = create_id2word(vocab)\n",
        "word2id = create_word2id(vocab)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gw7T9PTcTAUs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# extract feature vectors for training\n",
        "\n",
        "x_train = np.zeros( (len(X_train),2000), dtype=int)\n",
        "i = 0\n",
        "for address in X_train:\n",
        "  file = open('/content/aclImdb/train/'+address,'r')\n",
        "  txt = file.read().strip().lower()\n",
        "  words = txt.split()\n",
        "  for w in words:\n",
        "    if w in word2id:\n",
        "      x_train[i][word2id[w]] = 1\n",
        "  i += 1\n",
        "  \n",
        "# extract feature vectors for validation\n",
        "x_val = np.zeros( (len(X_val),2000), dtype=int)\n",
        "i = 0\n",
        "for address in X_val:\n",
        "  file = open('/content/aclImdb/train/'+address,'r')\n",
        "  txt = file.read().strip().lower()\n",
        "  words = txt.split()\n",
        "  for w in words:\n",
        "    if w in word2id:\n",
        "      x_val[i][word2id[w]] = 1\n",
        "  i += 1\n",
        "  \n",
        "# extract feature vectors for test\n",
        "x_test = np.zeros( (len(X_test),2000), dtype=int)\n",
        "i = 0\n",
        "for address in X_test:\n",
        "  file = open('/content/aclImdb/test/'+address,'r')\n",
        "  txt = file.read().strip().lower()\n",
        "  words = txt.split()\n",
        "  for w in words:\n",
        "    if w in word2id:\n",
        "      x_test[i][word2id[w]] = 1\n",
        "  i += 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HSPBFMZRaIa2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pickle\n",
        "\n",
        "\n",
        "y_train = np.asarray(y_train)\n",
        "y_val = np.asarray(y_val)\n",
        "y_test = np.asarray(y_test)\n",
        "\n",
        "# save the data into drive\n",
        "pickle.dump([x_train, y_train, x_val, y_val, x_test, y_test], open(\"data.pkl\", \"wb\")) \n",
        "pickle.dump([id2word, word2id],  open(\"aux.pkl\", \"wb\"))\n",
        "\n",
        "# load from the saved \n",
        "# x_train, y_train, x_val, y_val, x_test, y_test = pickle.load( open(\"data.pkl\", \"rb\"))\n",
        "# id2word, word2id = pickle.load( open(\"aux.pkl\", \"rb\"))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1H15W-wGb4JR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "class logistic_regression():\n",
        "  def __init__(self, batch_size = 20, learning_rate = 0.1, num_epochs = 300, threshhold = 0.5):\n",
        "    self.learning_rate = learning_rate\n",
        "    self.batch_size = batch_size\n",
        "    self.num_epochs = num_epochs\n",
        "    self.loss_list = []\n",
        "    self.threshhold = threshhold\n",
        "    \n",
        "  def set_training_data(self, X_train, y_train):\n",
        "    self.X_train = X_train #(20000, 2000)\n",
        "    self.y_train = y_train #(20000, )\n",
        "    \n",
        "  def set_validation_data(self, X_val, y_val):\n",
        "    self.X_val = X_val #(5000, 2000)\n",
        "    self.y_val = y_val #(5000, )\n",
        "    \n",
        "  def set_test_data(self, X_test, y_test):\n",
        "    self.X_test = X_test #(25000,2000) \n",
        "    self.y_test = y_test #(25000)\n",
        "\n",
        "  def init_weights(self):\n",
        "    self.W = np.random.uniform(-0.5 ,0.5 , 2000) #(2000, )\n",
        "    self.b = np.random.uniform(-0.5 ,0.5 , 1) #(1, )\n",
        "    self.bestW = np.random.uniform(-0.5 ,0.5 , 2000)\n",
        "\n",
        "\n",
        "  def train_model(self):\n",
        "    self.init_weights()\n",
        "    total_number_of_batches = int(self.X_train.shape[0] / self.batch_size)\n",
        "    self.loss_list = []\n",
        "    self.acc_train = []\n",
        "    self.acc_val = []\n",
        "    \n",
        "    prev_accuracy = 0\n",
        "\n",
        "    for i in range(self.num_epochs):\n",
        "      print(\"epoch \",i,\"-> \",end='')\n",
        "      total_loss = 0\n",
        "      for j in range(int(self.X_train.shape[0] / self.batch_size)):\n",
        "\n",
        "        X = self.X_train[self.batch_size*j : self.batch_size* (j+1)] # (batch_size, 2000)\n",
        "        y = self.y_train[self.batch_size*j : self.batch_size* (j+1)] # (batch_size, )\n",
        "\n",
        "        # calculating probabilities of X\n",
        "        h = (np.dot(X, self.W) + self.b) # (batch_size, )\n",
        "        prob = 1 / (1 + np.exp(-h)) # (batch_size, )\n",
        "        \n",
        "        # avoiding runtime warning for log(0)\n",
        "        for i in range(len(prob)):\n",
        "          if prob[i] == 0:\n",
        "            prob[i] = 10**(-10)\n",
        "          if prob[i] == 1:\n",
        "            prob[i] = 0.9999999999\n",
        "      \n",
        "        # calculating mean of loss for this batch\n",
        "        loss = np.mean( (-y * np.log(prob))  -  ((1-y) * np.log(1-prob)) )\n",
        "        # self.loss_list.append(loss)\n",
        "        total_loss += loss\n",
        "\n",
        "        # calculating gradient of loss for this batch (for weights and bias)\n",
        "        gradW = np.dot ((prob - y), X)\n",
        "        \n",
        "        # updating weights\n",
        "        self.W = self.W - self.learning_rate * gradW\n",
        "\n",
        "      #  get prediction for all train and validation data\n",
        "      predict_training = self.predict_label(self.X_train)\n",
        "      predict_validation = self.predict_label(self.X_val)\n",
        "      \n",
        "      # calculating training accuracy\n",
        "      counter = 0 \n",
        "      for i in range(len(predict_training)):\n",
        "        if predict_training[i] == self.y_train[i]:\n",
        "          counter += 1\n",
        "      train_acc = counter / len(predict_training)\n",
        "      self.acc_train.append(train_acc)\n",
        "      \n",
        "      # calculating validation accuracy\n",
        "      counter = 0 \n",
        "      for i in range(len(predict_validation)):\n",
        "        if predict_validation[i] == self.y_val[i]:\n",
        "          counter += 1\n",
        "      val_acc = counter / len(predict_validation)\n",
        "      self.acc_val.append(val_acc)\n",
        "                     \n",
        "      # use this list to create a plot for loss \n",
        "      self.loss_list.append(total_loss/total_number_of_batches)  \n",
        "      \n",
        "      print(\"train acc:\", train_acc, \"validation acc:\",val_acc, \"loss:\", total_loss/total_number_of_batches)\n",
        "      # compare with previous weights with respect to validation accuracy to find best model\n",
        "      if (prev_accuracy < val_acc):\n",
        "        prev_accuracy = val_acc\n",
        "        self.bestW = self.W\n",
        "  \n",
        "  def predict_label(self, x, bestW_flag = False):\n",
        "    \"\"\"make a prediction list of labels for x\"\"\"\n",
        "    if (not bestW_flag):\n",
        "      h = np.dot(x, self.W) + self.b\n",
        "      prob = 1 / (1 + np.exp(-h))\n",
        "      predict = np.empty_like(prob)\n",
        "      for i in range(len(prob)):\n",
        "        if prob[i] > self.threshhold :\n",
        "          predict[i] = 1\n",
        "        else:\n",
        "          predict[i] = 0\n",
        "    else:\n",
        "      h = np.dot(x, self.bestW) + self.b\n",
        "      prob = 1 / (1 + np.exp(-h))\n",
        "      predict = np.empty_like(prob)\n",
        "      for i in range(len(prob)):\n",
        "        if prob[i] > self.threshhold :\n",
        "          predict[i] = 1\n",
        "        else:\n",
        "          predict[i] = 0\n",
        "      \n",
        "    return predict\n",
        "    \n",
        "  def plot_loss(self):\n",
        "    \"\"\"plot the loss using loss list we gathered in training phase\"\"\"\n",
        "    plt.subplot(2,1,1)\n",
        "    plt.plot(self.loss_list)\n",
        "    plt.xlabel(\"iterations\")\n",
        "    plt.ylabel(\"loss\")\n",
        "  \n",
        "  def plot_accuracy(self):\n",
        "    plt.subplot(2,1,2)\n",
        "    plt.plot(self.acc_train, label= 'train accuracy')\n",
        "    plt.plot(self.acc_val, label= 'validation accuracy')    \n",
        "    plt.xlabel(\"iterations\")\n",
        "    plt.legend(loc='best')\n",
        "\n",
        "    \n",
        "  def test_best_model(self):\n",
        "    predict_test = self.predict_label(self.X_test, bestW_flag = True)\n",
        "    counter = 0 \n",
        "    for i in range(len(predict_test)):\n",
        "      if predict_test[i] == self.y_test[i]:\n",
        "        counter += 1\n",
        "    test_accuracy = counter / len(predict_test)\n",
        "  \n",
        "    return test_accuracy\n",
        "  \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SZwWIH_tHyMx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "7ec98cda-2db6-4a29-fb05-cdd30d974a44"
      },
      "source": [
        "if __name__ == \"__main__\":\n",
        "  lr = logistic_regression(batch_size = 20, learning_rate = 0.1, num_epochs = 300)\n",
        "  lr.set_training_data(x_train, y_train)\n",
        "  lr.set_validation_data(x_val, y_val)\n",
        "  lr.set_test_data(x_test, y_test)\n",
        "  lr.train_model()\n",
        "  lr.plot_loss()\n",
        "  lr.plot_accuracy()\n",
        "  print(\"test accuracy for best model: \", lr.test_best_model())"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch  0 -> train acc: 0.8312 validation acc: 0.805 loss: 1.5305812867776805\n",
            "epoch  1 -> train acc: 0.84855 validation acc: 0.8172 loss: 0.9718467597379356\n",
            "epoch  2 -> train acc: 0.8383 validation acc: 0.8032 loss: 0.9329752777494724\n",
            "epoch  3 -> train acc: 0.85005 validation acc: 0.8144 loss: 0.9092767247062254\n",
            "epoch  4 -> train acc: 0.85115 validation acc: 0.814 loss: 0.8783582385383749\n",
            "epoch  5 -> train acc: 0.83425 validation acc: 0.8004 loss: 0.9072449570102002\n",
            "epoch  6 -> train acc: 0.8553 validation acc: 0.8158 loss: 0.8904013869838501\n",
            "epoch  7 -> train acc: 0.84475 validation acc: 0.8086 loss: 0.8926362654374177\n",
            "epoch  8 -> train acc: 0.8657 validation acc: 0.8212 loss: 0.8959659862608909\n",
            "epoch  9 -> train acc: 0.8416 validation acc: 0.8082 loss: 0.8769148797247277\n",
            "epoch  10 -> train acc: 0.8613 validation acc: 0.8212 loss: 0.907335965614923\n",
            "epoch  11 -> train acc: 0.84245 validation acc: 0.808 loss: 0.8800255947422656\n",
            "epoch  12 -> train acc: 0.8574 validation acc: 0.8186 loss: 0.8682104868069318\n",
            "epoch  13 -> train acc: 0.86675 validation acc: 0.8262 loss: 0.8924686951959965\n",
            "epoch  14 -> train acc: 0.86335 validation acc: 0.8194 loss: 0.8762390134643196\n",
            "epoch  15 -> train acc: 0.86535 validation acc: 0.8192 loss: 0.8757570031057674\n",
            "epoch  16 -> train acc: 0.8608 validation acc: 0.8218 loss: 0.8771663582590783\n",
            "epoch  17 -> train acc: 0.86835 validation acc: 0.8188 loss: 0.8956872297797148\n",
            "epoch  18 -> train acc: 0.8657 validation acc: 0.816 loss: 0.8708615821912371\n",
            "epoch  19 -> train acc: 0.86955 validation acc: 0.8228 loss: 0.8806729357352512\n",
            "epoch  20 -> train acc: 0.87025 validation acc: 0.8216 loss: 0.8768818688336742\n",
            "epoch  21 -> train acc: 0.85205 validation acc: 0.815 loss: 0.8835365125395267\n",
            "epoch  22 -> train acc: 0.8674 validation acc: 0.823 loss: 0.8747616227274834\n",
            "epoch  23 -> train acc: 0.8631 validation acc: 0.8204 loss: 0.8837915708791771\n",
            "epoch  24 -> train acc: 0.86855 validation acc: 0.8194 loss: 0.8738914058892636\n",
            "epoch  25 -> train acc: 0.87025 validation acc: 0.8218 loss: 0.8777960545745043\n",
            "epoch  26 -> train acc: 0.8524 validation acc: 0.8134 loss: 0.8800356206712542\n",
            "epoch  27 -> train acc: 0.86975 validation acc: 0.8212 loss: 0.8716173519981464\n",
            "epoch  28 -> train acc: 0.8646 validation acc: 0.8206 loss: 0.9033093797351954\n",
            "epoch  29 -> train acc: 0.86325 validation acc: 0.8228 loss: 0.8807380031728856\n",
            "epoch  30 -> train acc: 0.86815 validation acc: 0.821 loss: 0.8871563194610326\n",
            "epoch  31 -> train acc: 0.87025 validation acc: 0.8242 loss: 0.8851461435085615\n",
            "epoch  32 -> train acc: 0.86215 validation acc: 0.8198 loss: 0.8677540832712735\n",
            "epoch  33 -> train acc: 0.8714 validation acc: 0.8194 loss: 0.8818209975328433\n",
            "epoch  34 -> train acc: 0.86635 validation acc: 0.8176 loss: 0.8633147632253129\n",
            "epoch  35 -> train acc: 0.8672 validation acc: 0.8236 loss: 0.8933891929382725\n",
            "epoch  36 -> train acc: 0.8591 validation acc: 0.8204 loss: 0.890721856589036\n",
            "epoch  37 -> train acc: 0.86395 validation acc: 0.8162 loss: 0.8657622007064946\n",
            "epoch  38 -> train acc: 0.87045 validation acc: 0.8162 loss: 0.8664587630290261\n",
            "epoch  39 -> train acc: 0.8606 validation acc: 0.8204 loss: 0.8770786847966181\n",
            "epoch  40 -> train acc: 0.87015 validation acc: 0.8246 loss: 0.8815434197163081\n",
            "epoch  41 -> train acc: 0.8683 validation acc: 0.8218 loss: 0.8736432875110994\n",
            "epoch  42 -> train acc: 0.86945 validation acc: 0.8178 loss: 0.8860293197456535\n",
            "epoch  43 -> train acc: 0.86875 validation acc: 0.8202 loss: 0.8755723727224597\n",
            "epoch  44 -> train acc: 0.8643 validation acc: 0.819 loss: 0.8665832256843438\n",
            "epoch  45 -> train acc: 0.8672 validation acc: 0.8186 loss: 0.891326388039896\n",
            "epoch  46 -> train acc: 0.86265 validation acc: 0.8152 loss: 0.8799537717648105\n",
            "epoch  47 -> train acc: 0.86915 validation acc: 0.8226 loss: 0.8695197020277103\n",
            "epoch  48 -> train acc: 0.86635 validation acc: 0.8196 loss: 0.893337251772261\n",
            "epoch  49 -> train acc: 0.8538 validation acc: 0.818 loss: 0.8812897967895439\n",
            "epoch  50 -> train acc: 0.86965 validation acc: 0.8226 loss: 0.8815980259850332\n",
            "epoch  51 -> train acc: 0.86955 validation acc: 0.8204 loss: 0.8758064429788165\n",
            "epoch  52 -> train acc: 0.8569 validation acc: 0.8176 loss: 0.8762713602153839\n",
            "epoch  53 -> train acc: 0.8657 validation acc: 0.8226 loss: 0.8858851281953817\n",
            "epoch  54 -> train acc: 0.86955 validation acc: 0.8198 loss: 0.8763728961693964\n",
            "epoch  55 -> train acc: 0.8649 validation acc: 0.8198 loss: 0.8769784500115121\n",
            "epoch  56 -> train acc: 0.86545 validation acc: 0.8186 loss: 0.8748652718734768\n",
            "epoch  57 -> train acc: 0.8683 validation acc: 0.8148 loss: 0.8730866516351414\n",
            "epoch  58 -> train acc: 0.86835 validation acc: 0.824 loss: 0.867211033627128\n",
            "epoch  59 -> train acc: 0.8635 validation acc: 0.822 loss: 0.896808621893295\n",
            "epoch  60 -> train acc: 0.87195 validation acc: 0.819 loss: 0.8796770085466401\n",
            "epoch  61 -> train acc: 0.865 validation acc: 0.8218 loss: 0.8807906647158057\n",
            "epoch  62 -> train acc: 0.8643 validation acc: 0.8172 loss: 0.8758390658752847\n",
            "epoch  63 -> train acc: 0.8722 validation acc: 0.8182 loss: 0.875758002827528\n",
            "epoch  64 -> train acc: 0.86865 validation acc: 0.8212 loss: 0.8764791170189508\n",
            "epoch  65 -> train acc: 0.8676 validation acc: 0.8232 loss: 0.8706494776209287\n",
            "epoch  66 -> train acc: 0.8691 validation acc: 0.8206 loss: 0.884276144530965\n",
            "epoch  67 -> train acc: 0.86205 validation acc: 0.8228 loss: 0.887760756251297\n",
            "epoch  68 -> train acc: 0.86425 validation acc: 0.8212 loss: 0.8860708782003884\n",
            "epoch  69 -> train acc: 0.8681 validation acc: 0.8212 loss: 0.8814694542549426\n",
            "epoch  70 -> train acc: 0.8646 validation acc: 0.8194 loss: 0.8752382444762721\n",
            "epoch  71 -> train acc: 0.86015 validation acc: 0.8148 loss: 0.889438220707337\n",
            "epoch  72 -> train acc: 0.8665 validation acc: 0.8198 loss: 0.8703359682068554\n",
            "epoch  73 -> train acc: 0.8605 validation acc: 0.8178 loss: 0.8793110781441708\n",
            "epoch  74 -> train acc: 0.8707 validation acc: 0.8182 loss: 0.8861303798062481\n",
            "epoch  75 -> train acc: 0.868 validation acc: 0.8192 loss: 0.881066477109458\n",
            "epoch  76 -> train acc: 0.86215 validation acc: 0.818 loss: 0.8827084465297207\n",
            "epoch  77 -> train acc: 0.85635 validation acc: 0.8132 loss: 0.8787225945788059\n",
            "epoch  78 -> train acc: 0.86435 validation acc: 0.8192 loss: 0.8739711468247606\n",
            "epoch  79 -> train acc: 0.86435 validation acc: 0.8242 loss: 0.896550847317358\n",
            "epoch  80 -> train acc: 0.87305 validation acc: 0.8226 loss: 0.8843831333755071\n",
            "epoch  81 -> train acc: 0.8613 validation acc: 0.8198 loss: 0.8657229079245906\n",
            "epoch  82 -> train acc: 0.8648 validation acc: 0.82 loss: 0.8832333195592337\n",
            "epoch  83 -> train acc: 0.8597 validation acc: 0.8188 loss: 0.8918237469192704\n",
            "epoch  84 -> train acc: 0.86805 validation acc: 0.8222 loss: 0.8877047287037485\n",
            "epoch  85 -> train acc: 0.8642 validation acc: 0.8168 loss: 0.8764116078426322\n",
            "epoch  86 -> train acc: 0.87295 validation acc: 0.8222 loss: 0.873863072603901\n",
            "epoch  87 -> train acc: 0.8573 validation acc: 0.8162 loss: 0.8755918764224944\n",
            "epoch  88 -> train acc: 0.86605 validation acc: 0.8194 loss: 0.8852284967550217\n",
            "epoch  89 -> train acc: 0.8644 validation acc: 0.8206 loss: 0.8820987945107045\n",
            "epoch  90 -> train acc: 0.8683 validation acc: 0.8212 loss: 0.8849982492538494\n",
            "epoch  91 -> train acc: 0.87235 validation acc: 0.8204 loss: 0.8989643567056341\n",
            "epoch  92 -> train acc: 0.85885 validation acc: 0.8178 loss: 0.8733331184599147\n",
            "epoch  93 -> train acc: 0.8665 validation acc: 0.8192 loss: 0.8706710423357811\n",
            "epoch  94 -> train acc: 0.86595 validation acc: 0.8186 loss: 0.8915941206052338\n",
            "epoch  95 -> train acc: 0.8616 validation acc: 0.819 loss: 0.8740333194181762\n",
            "epoch  96 -> train acc: 0.87 validation acc: 0.8204 loss: 0.8756538010597918\n",
            "epoch  97 -> train acc: 0.86155 validation acc: 0.8236 loss: 0.8891263038052757\n",
            "epoch  98 -> train acc: 0.85945 validation acc: 0.817 loss: 0.8909753899159879\n",
            "epoch  99 -> train acc: 0.86955 validation acc: 0.8196 loss: 0.8690461964449118\n",
            "epoch  100 -> train acc: 0.86395 validation acc: 0.8174 loss: 0.8851360999732171\n",
            "epoch  101 -> train acc: 0.85595 validation acc: 0.8128 loss: 0.885245795489678\n",
            "epoch  102 -> train acc: 0.8633 validation acc: 0.8172 loss: 0.8861824556464096\n",
            "epoch  103 -> train acc: 0.86405 validation acc: 0.8184 loss: 0.8751426746019965\n",
            "epoch  104 -> train acc: 0.8704 validation acc: 0.8224 loss: 0.8771174839282893\n",
            "epoch  105 -> train acc: 0.86145 validation acc: 0.8194 loss: 0.887564530559279\n",
            "epoch  106 -> train acc: 0.86515 validation acc: 0.8192 loss: 0.8856101865377594\n",
            "epoch  107 -> train acc: 0.86605 validation acc: 0.8186 loss: 0.8851226175793022\n",
            "epoch  108 -> train acc: 0.86435 validation acc: 0.82 loss: 0.8657821947230897\n",
            "epoch  109 -> train acc: 0.8721 validation acc: 0.819 loss: 0.8813458099129015\n",
            "epoch  110 -> train acc: 0.85895 validation acc: 0.8162 loss: 0.8691494664775674\n",
            "epoch  111 -> train acc: 0.86755 validation acc: 0.8196 loss: 0.8927386308083523\n",
            "epoch  112 -> train acc: 0.84875 validation acc: 0.8106 loss: 0.8800138166114377\n",
            "epoch  113 -> train acc: 0.8667 validation acc: 0.8182 loss: 0.8868415665130587\n",
            "epoch  114 -> train acc: 0.86805 validation acc: 0.8238 loss: 0.8779724782777486\n",
            "epoch  115 -> train acc: 0.8688 validation acc: 0.8214 loss: 0.8927565217331757\n",
            "epoch  116 -> train acc: 0.8667 validation acc: 0.8194 loss: 0.8669831158436149\n",
            "epoch  117 -> train acc: 0.86695 validation acc: 0.8218 loss: 0.8721721574301933\n",
            "epoch  118 -> train acc: 0.86405 validation acc: 0.8168 loss: 0.8762142281605022\n",
            "epoch  119 -> train acc: 0.8616 validation acc: 0.8188 loss: 0.8697507527187315\n",
            "epoch  120 -> train acc: 0.8693 validation acc: 0.8196 loss: 0.8968394306607091\n",
            "epoch  121 -> train acc: 0.85785 validation acc: 0.82 loss: 0.8753253542964936\n",
            "epoch  122 -> train acc: 0.86765 validation acc: 0.8198 loss: 0.8858726671208695\n",
            "epoch  123 -> train acc: 0.85545 validation acc: 0.813 loss: 0.8785310955641996\n",
            "epoch  124 -> train acc: 0.86645 validation acc: 0.8178 loss: 0.8715566883054385\n",
            "epoch  125 -> train acc: 0.8674 validation acc: 0.8254 loss: 0.8809063185121683\n",
            "epoch  126 -> train acc: 0.86325 validation acc: 0.8152 loss: 0.8743714909250864\n",
            "epoch  127 -> train acc: 0.86745 validation acc: 0.8206 loss: 0.8797949532609375\n",
            "epoch  128 -> train acc: 0.8665 validation acc: 0.8206 loss: 0.8802880643952619\n",
            "epoch  129 -> train acc: 0.865 validation acc: 0.8166 loss: 0.8849214826931368\n",
            "epoch  130 -> train acc: 0.86975 validation acc: 0.822 loss: 0.8648531325560461\n",
            "epoch  131 -> train acc: 0.86955 validation acc: 0.8202 loss: 0.8713546878677647\n",
            "epoch  132 -> train acc: 0.8702 validation acc: 0.8206 loss: 0.8797671138792712\n",
            "epoch  133 -> train acc: 0.8672 validation acc: 0.8186 loss: 0.8834679148732864\n",
            "epoch  134 -> train acc: 0.8671 validation acc: 0.8186 loss: 0.8770890296015081\n",
            "epoch  135 -> train acc: 0.8616 validation acc: 0.82 loss: 0.8848093596780185\n",
            "epoch  136 -> train acc: 0.86535 validation acc: 0.817 loss: 0.8760814317751728\n",
            "epoch  137 -> train acc: 0.869 validation acc: 0.822 loss: 0.8764519086211494\n",
            "epoch  138 -> train acc: 0.86575 validation acc: 0.82 loss: 0.8936413935246398\n",
            "epoch  139 -> train acc: 0.8651 validation acc: 0.8198 loss: 0.8812143718617446\n",
            "epoch  140 -> train acc: 0.868 validation acc: 0.8198 loss: 0.8926016522526761\n",
            "epoch  141 -> train acc: 0.8627 validation acc: 0.8166 loss: 0.8796127092918244\n",
            "epoch  142 -> train acc: 0.8667 validation acc: 0.8206 loss: 0.8649153088325211\n",
            "epoch  143 -> train acc: 0.8622 validation acc: 0.818 loss: 0.8924680176127138\n",
            "epoch  144 -> train acc: 0.8672 validation acc: 0.8202 loss: 0.8772382077378358\n",
            "epoch  145 -> train acc: 0.86695 validation acc: 0.8178 loss: 0.8827112159071582\n",
            "epoch  146 -> train acc: 0.85595 validation acc: 0.816 loss: 0.8734124002193691\n",
            "epoch  147 -> train acc: 0.8694 validation acc: 0.8204 loss: 0.8799300830036446\n",
            "epoch  148 -> train acc: 0.87125 validation acc: 0.8216 loss: 0.8806288208820395\n",
            "epoch  149 -> train acc: 0.8692 validation acc: 0.8218 loss: 0.8786997439917412\n",
            "epoch  150 -> train acc: 0.869 validation acc: 0.8222 loss: 0.8737347690091771\n",
            "epoch  151 -> train acc: 0.86765 validation acc: 0.8208 loss: 0.8773470311738082\n",
            "epoch  152 -> train acc: 0.8694 validation acc: 0.8212 loss: 0.8738971209491464\n",
            "epoch  153 -> train acc: 0.86595 validation acc: 0.8194 loss: 0.8778155305402022\n",
            "epoch  154 -> train acc: 0.85055 validation acc: 0.8128 loss: 0.8883797836685766\n",
            "epoch  155 -> train acc: 0.86835 validation acc: 0.8204 loss: 0.8657386565881057\n",
            "epoch  156 -> train acc: 0.86845 validation acc: 0.8178 loss: 0.8830859593041368\n",
            "epoch  157 -> train acc: 0.86955 validation acc: 0.819 loss: 0.8684209331903595\n",
            "epoch  158 -> train acc: 0.8654 validation acc: 0.8204 loss: 0.873131761742542\n",
            "epoch  159 -> train acc: 0.86605 validation acc: 0.8204 loss: 0.891276182699482\n",
            "epoch  160 -> train acc: 0.86 validation acc: 0.8176 loss: 0.8760639975205068\n",
            "epoch  161 -> train acc: 0.86885 validation acc: 0.8202 loss: 0.8986677693744999\n",
            "epoch  162 -> train acc: 0.869 validation acc: 0.8176 loss: 0.8615483105004723\n",
            "epoch  163 -> train acc: 0.8629 validation acc: 0.816 loss: 0.8815453639640302\n",
            "epoch  164 -> train acc: 0.86325 validation acc: 0.8186 loss: 0.8855059675159468\n",
            "epoch  165 -> train acc: 0.8652 validation acc: 0.8216 loss: 0.8725883638431813\n",
            "epoch  166 -> train acc: 0.86445 validation acc: 0.8188 loss: 0.8878468121791006\n",
            "epoch  167 -> train acc: 0.8698 validation acc: 0.8214 loss: 0.8769818739909208\n",
            "epoch  168 -> train acc: 0.86295 validation acc: 0.8182 loss: 0.8837786467343145\n",
            "epoch  169 -> train acc: 0.86105 validation acc: 0.8168 loss: 0.88174044477916\n",
            "epoch  170 -> train acc: 0.85995 validation acc: 0.815 loss: 0.8753488380201607\n",
            "epoch  171 -> train acc: 0.85825 validation acc: 0.8186 loss: 0.8727347099419384\n",
            "epoch  172 -> train acc: 0.86545 validation acc: 0.8196 loss: 0.8757268699685455\n",
            "epoch  173 -> train acc: 0.86265 validation acc: 0.8234 loss: 0.8895200266963359\n",
            "epoch  174 -> train acc: 0.8593 validation acc: 0.8174 loss: 0.8739896164439894\n",
            "epoch  175 -> train acc: 0.87065 validation acc: 0.8218 loss: 0.8848877008562485\n",
            "epoch  176 -> train acc: 0.865 validation acc: 0.8204 loss: 0.8918116774442415\n",
            "epoch  177 -> train acc: 0.8611 validation acc: 0.813 loss: 0.8841056230666972\n",
            "epoch  178 -> train acc: 0.8678 validation acc: 0.8234 loss: 0.8872198036148914\n",
            "epoch  179 -> train acc: 0.86825 validation acc: 0.8188 loss: 0.8784778555979349\n",
            "epoch  180 -> train acc: 0.8648 validation acc: 0.8214 loss: 0.870483420202558\n",
            "epoch  181 -> train acc: 0.8655 validation acc: 0.8208 loss: 0.8759034460976323\n",
            "epoch  182 -> train acc: 0.86415 validation acc: 0.821 loss: 0.887482747820906\n",
            "epoch  183 -> train acc: 0.85795 validation acc: 0.8144 loss: 0.8793799546388553\n",
            "epoch  184 -> train acc: 0.8718 validation acc: 0.821 loss: 0.8854278771788741\n",
            "epoch  185 -> train acc: 0.8682 validation acc: 0.817 loss: 0.8786580153114539\n",
            "epoch  186 -> train acc: 0.86875 validation acc: 0.8218 loss: 0.8818336656360639\n",
            "epoch  187 -> train acc: 0.8717 validation acc: 0.8216 loss: 0.8927133166637011\n",
            "epoch  188 -> train acc: 0.862 validation acc: 0.8206 loss: 0.8839359831710746\n",
            "epoch  189 -> train acc: 0.86465 validation acc: 0.819 loss: 0.8809371224705458\n",
            "epoch  190 -> train acc: 0.86715 validation acc: 0.818 loss: 0.874015773228907\n",
            "epoch  191 -> train acc: 0.8683 validation acc: 0.8208 loss: 0.8879200904562354\n",
            "epoch  192 -> train acc: 0.86615 validation acc: 0.8182 loss: 0.880901026374662\n",
            "epoch  193 -> train acc: 0.86305 validation acc: 0.8184 loss: 0.8803135719316466\n",
            "epoch  194 -> train acc: 0.87025 validation acc: 0.8204 loss: 0.8791768478138017\n",
            "epoch  195 -> train acc: 0.86275 validation acc: 0.8226 loss: 0.8719518714436941\n",
            "epoch  196 -> train acc: 0.86985 validation acc: 0.8228 loss: 0.880315448961463\n",
            "epoch  197 -> train acc: 0.8688 validation acc: 0.818 loss: 0.8865977593940215\n",
            "epoch  198 -> train acc: 0.85945 validation acc: 0.8174 loss: 0.8751529257527055\n",
            "epoch  199 -> train acc: 0.87005 validation acc: 0.8202 loss: 0.8742754022964498\n",
            "epoch  200 -> train acc: 0.8655 validation acc: 0.8212 loss: 0.8778272914139772\n",
            "epoch  201 -> train acc: 0.8632 validation acc: 0.8148 loss: 0.8705157045969507\n",
            "epoch  202 -> train acc: 0.86825 validation acc: 0.8228 loss: 0.8942308446756287\n",
            "epoch  203 -> train acc: 0.8675 validation acc: 0.8216 loss: 0.8674199983709597\n",
            "epoch  204 -> train acc: 0.8652 validation acc: 0.8158 loss: 0.8660074822481282\n",
            "epoch  205 -> train acc: 0.86865 validation acc: 0.8194 loss: 0.8845048465251292\n",
            "epoch  206 -> train acc: 0.86465 validation acc: 0.8216 loss: 0.8791966430530187\n",
            "epoch  207 -> train acc: 0.8621 validation acc: 0.8188 loss: 0.8803984314664961\n",
            "epoch  208 -> train acc: 0.8684 validation acc: 0.8228 loss: 0.8892972804447415\n",
            "epoch  209 -> train acc: 0.8608 validation acc: 0.8162 loss: 0.8890753954423558\n",
            "epoch  210 -> train acc: 0.8647 validation acc: 0.8198 loss: 0.8748505150929217\n",
            "epoch  211 -> train acc: 0.8672 validation acc: 0.8168 loss: 0.8707609555699591\n",
            "epoch  212 -> train acc: 0.8662 validation acc: 0.8224 loss: 0.8752510449508291\n",
            "epoch  213 -> train acc: 0.8724 validation acc: 0.8176 loss: 0.8720644840911387\n",
            "epoch  214 -> train acc: 0.86925 validation acc: 0.822 loss: 0.8863370872528955\n",
            "epoch  215 -> train acc: 0.8656 validation acc: 0.8212 loss: 0.8627728676507451\n",
            "epoch  216 -> train acc: 0.86655 validation acc: 0.818 loss: 0.8689146061195552\n",
            "epoch  217 -> train acc: 0.86605 validation acc: 0.8176 loss: 0.8921841508362559\n",
            "epoch  218 -> train acc: 0.8625 validation acc: 0.819 loss: 0.8880338168140978\n",
            "epoch  219 -> train acc: 0.8716 validation acc: 0.8212 loss: 0.8785739824195379\n",
            "epoch  220 -> train acc: 0.8637 validation acc: 0.8172 loss: 0.8846672601606838\n",
            "epoch  221 -> train acc: 0.87005 validation acc: 0.8188 loss: 0.8767935969410097\n",
            "epoch  222 -> train acc: 0.8682 validation acc: 0.8186 loss: 0.8772227729834899\n",
            "epoch  223 -> train acc: 0.8672 validation acc: 0.8156 loss: 0.8877338779630483\n",
            "epoch  224 -> train acc: 0.87275 validation acc: 0.8208 loss: 0.8767688633707074\n",
            "epoch  225 -> train acc: 0.86905 validation acc: 0.8228 loss: 0.8840415951812243\n",
            "epoch  226 -> train acc: 0.8694 validation acc: 0.8194 loss: 0.8827549698769271\n",
            "epoch  227 -> train acc: 0.8637 validation acc: 0.817 loss: 0.8774865934866563\n",
            "epoch  228 -> train acc: 0.86295 validation acc: 0.8208 loss: 0.8721657762478097\n",
            "epoch  229 -> train acc: 0.8697 validation acc: 0.822 loss: 0.8911418693999246\n",
            "epoch  230 -> train acc: 0.8699 validation acc: 0.8202 loss: 0.8653620977632348\n",
            "epoch  231 -> train acc: 0.86835 validation acc: 0.8188 loss: 0.8826921561056086\n",
            "epoch  232 -> train acc: 0.8617 validation acc: 0.8148 loss: 0.8747556143712532\n",
            "epoch  233 -> train acc: 0.86645 validation acc: 0.8172 loss: 0.8838377515053727\n",
            "epoch  234 -> train acc: 0.86975 validation acc: 0.8234 loss: 0.8677153721394852\n",
            "epoch  235 -> train acc: 0.865 validation acc: 0.8196 loss: 0.880306656297198\n",
            "epoch  236 -> train acc: 0.87175 validation acc: 0.8222 loss: 0.892876878927272\n",
            "epoch  237 -> train acc: 0.8685 validation acc: 0.8224 loss: 0.8814558239419862\n",
            "epoch  238 -> train acc: 0.86965 validation acc: 0.8202 loss: 0.8669077174379441\n",
            "epoch  239 -> train acc: 0.8636 validation acc: 0.821 loss: 0.8850594383146159\n",
            "epoch  240 -> train acc: 0.86215 validation acc: 0.8176 loss: 0.8863716267230695\n",
            "epoch  241 -> train acc: 0.8655 validation acc: 0.818 loss: 0.8768749391018658\n",
            "epoch  242 -> train acc: 0.86345 validation acc: 0.8184 loss: 0.8916800067267573\n",
            "epoch  243 -> train acc: 0.8706 validation acc: 0.82 loss: 0.8742687902094741\n",
            "epoch  244 -> train acc: 0.86675 validation acc: 0.8196 loss: 0.8698263267073559\n",
            "epoch  245 -> train acc: 0.8657 validation acc: 0.8218 loss: 0.887480864973114\n",
            "epoch  246 -> train acc: 0.86605 validation acc: 0.8222 loss: 0.8625011464444683\n",
            "epoch  247 -> train acc: 0.86415 validation acc: 0.8198 loss: 0.8864781963591296\n",
            "epoch  248 -> train acc: 0.8664 validation acc: 0.821 loss: 0.8816966509580718\n",
            "epoch  249 -> train acc: 0.86485 validation acc: 0.8192 loss: 0.8780555172856158\n",
            "epoch  250 -> train acc: 0.86095 validation acc: 0.8148 loss: 0.8779700398805905\n",
            "epoch  251 -> train acc: 0.8641 validation acc: 0.822 loss: 0.8845107598279343\n",
            "epoch  252 -> train acc: 0.869 validation acc: 0.8202 loss: 0.8804277681964873\n",
            "epoch  253 -> train acc: 0.86575 validation acc: 0.8212 loss: 0.888993803478861\n",
            "epoch  254 -> train acc: 0.87315 validation acc: 0.8204 loss: 0.8858909549863889\n",
            "epoch  255 -> train acc: 0.8716 validation acc: 0.8212 loss: 0.869568439446925\n",
            "epoch  256 -> train acc: 0.86245 validation acc: 0.8184 loss: 0.8952015032485799\n",
            "epoch  257 -> train acc: 0.84615 validation acc: 0.8082 loss: 0.8747400666124516\n",
            "epoch  258 -> train acc: 0.8649 validation acc: 0.8198 loss: 0.872880715385705\n",
            "epoch  259 -> train acc: 0.8698 validation acc: 0.8244 loss: 0.878473917178504\n",
            "epoch  260 -> train acc: 0.86935 validation acc: 0.8206 loss: 0.8803191421509431\n",
            "epoch  261 -> train acc: 0.86915 validation acc: 0.8204 loss: 0.8801993900872052\n",
            "epoch  262 -> train acc: 0.86465 validation acc: 0.8206 loss: 0.8839433176807563\n",
            "epoch  263 -> train acc: 0.87105 validation acc: 0.8182 loss: 0.8722790783421848\n",
            "epoch  264 -> train acc: 0.87 validation acc: 0.8224 loss: 0.86780853518392\n",
            "epoch  265 -> train acc: 0.8631 validation acc: 0.822 loss: 0.8803754863832589\n",
            "epoch  266 -> train acc: 0.8638 validation acc: 0.819 loss: 0.8885203817376068\n",
            "epoch  267 -> train acc: 0.86595 validation acc: 0.82 loss: 0.8752119569142969\n",
            "epoch  268 -> train acc: 0.86835 validation acc: 0.8222 loss: 0.8985713937972908\n",
            "epoch  269 -> train acc: 0.87085 validation acc: 0.8212 loss: 0.8764075770191025\n",
            "epoch  270 -> train acc: 0.8553 validation acc: 0.8126 loss: 0.8928198733626812\n",
            "epoch  271 -> train acc: 0.87105 validation acc: 0.8212 loss: 0.8703042732223928\n",
            "epoch  272 -> train acc: 0.8636 validation acc: 0.8172 loss: 0.8749023772069168\n",
            "epoch  273 -> train acc: 0.86695 validation acc: 0.823 loss: 0.875532586686613\n",
            "epoch  274 -> train acc: 0.86185 validation acc: 0.8222 loss: 0.8883685185622086\n",
            "epoch  275 -> train acc: 0.8588 validation acc: 0.8142 loss: 0.887021195225727\n",
            "epoch  276 -> train acc: 0.86345 validation acc: 0.8184 loss: 0.8582094448050973\n",
            "epoch  277 -> train acc: 0.868 validation acc: 0.8224 loss: 0.8847271222601629\n",
            "epoch  278 -> train acc: 0.8659 validation acc: 0.821 loss: 0.884912206851652\n",
            "epoch  279 -> train acc: 0.8595 validation acc: 0.8184 loss: 0.8748930635872727\n",
            "epoch  280 -> train acc: 0.86895 validation acc: 0.82 loss: 0.8750714353022703\n",
            "epoch  281 -> train acc: 0.86675 validation acc: 0.8244 loss: 0.8952137236733522\n",
            "epoch  282 -> train acc: 0.8703 validation acc: 0.8218 loss: 0.8906397108137332\n",
            "epoch  283 -> train acc: 0.8627 validation acc: 0.8162 loss: 0.8656835007343202\n",
            "epoch  284 -> train acc: 0.8683 validation acc: 0.8222 loss: 0.8786779366121129\n",
            "epoch  285 -> train acc: 0.8679 validation acc: 0.8158 loss: 0.8726214093122873\n",
            "epoch  286 -> train acc: 0.86585 validation acc: 0.819 loss: 0.888184406380207\n",
            "epoch  287 -> train acc: 0.8641 validation acc: 0.8172 loss: 0.8724903394411367\n",
            "epoch  288 -> train acc: 0.86935 validation acc: 0.8228 loss: 0.8942437887940468\n",
            "epoch  289 -> train acc: 0.8712 validation acc: 0.8232 loss: 0.8721928746865706\n",
            "epoch  290 -> train acc: 0.8704 validation acc: 0.8234 loss: 0.8838686565069133\n",
            "epoch  291 -> train acc: 0.871 validation acc: 0.8202 loss: 0.8839420684062017\n",
            "epoch  292 -> train acc: 0.86725 validation acc: 0.8222 loss: 0.873687784886038\n",
            "epoch  293 -> train acc: 0.8618 validation acc: 0.8186 loss: 0.8714387442238113\n",
            "epoch  294 -> train acc: 0.8681 validation acc: 0.8194 loss: 0.8874581589063654\n",
            "epoch  295 -> train acc: 0.86615 validation acc: 0.8206 loss: 0.8767694303765774\n",
            "epoch  296 -> train acc: 0.87125 validation acc: 0.8246 loss: 0.8864672095343565\n",
            "epoch  297 -> train acc: 0.86355 validation acc: 0.8168 loss: 0.8631999103132801\n",
            "epoch  298 -> train acc: 0.8685 validation acc: 0.8232 loss: 0.8872946733384549\n",
            "epoch  299 -> train acc: 0.86405 validation acc: 0.819 loss: 0.8743797773980153\n",
            "test accuracy for best model:  0.82524\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEKCAYAAAD9xUlFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}